{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                          statement\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/'\n",
    "df = pd.read_csv(data_path + 'FinancialPB.csv',header=None ,encoding='ISO-8859-1')\n",
    "df.columns =['sentiment' ,'statement']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4838, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['statement'],keep='first',inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(df['sentiment'].value_counts().index, df['sentiment'].value_counts().values, alpha=0.8)\n",
    "plt.ylabel('Counts', fontsize=12)\n",
    "plt.xlabel('sentiment', fontsize=12)\n",
    "plt.xticks()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>statement</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                          statement  \\\n",
       "0   neutral  According to Gran , the company has no plans t...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company 's updated strategy f...   \n",
       "\n",
       "   sentiment_encoded  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  2  \n",
       "4                  2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_encoded'] = LabelEncoder().fit_transform(df['sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/taojin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#stopwords removal\n",
    "nltk.download('stopwords')\n",
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuations\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, STOPWORDS):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "def stem_words(text, stemmer):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "def remove_freqwords(text, FREQWORDS):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "def lemmatize_words(text, lemmatizer, wordnet_map ):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "def clean_review(text):\n",
    "    clean_text = []\n",
    "    for w in word_tokenize(text):\n",
    "        if w.lower() not in stop:\n",
    "            pos = pos_tag([w])\n",
    "            new_w = lemmatizer.lemmatize(w, pos=get_simple_pos(pos[0][1]))\n",
    "            clean_text.append(new_w)\n",
    "    return clean_text\n",
    "\n",
    "def join_text(text):\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['statement'] = df['statement'].apply(lambda x: remove_punct(x))\n",
    "STOPWORDS = set(\", \".join(stopwords.words('english')))\n",
    "df['non_stop_statement'] = df['statement'].apply(lambda x: remove_stopwords(x, STOPWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_statement'] = df['non_stop_statement'].apply(lambda x: stem_words(x,PorterStemmer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 6059),\n",
       " ('of', 3199),\n",
       " ('in', 2747),\n",
       " ('and', 2587),\n",
       " ('to', 2493),\n",
       " ('eur', 1310),\n",
       " ('for', 1150),\n",
       " ('it', 999),\n",
       " ('compani', 967),\n",
       " ('is', 920)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove frequent words \n",
    "fre_count = Counter()\n",
    "for phrase in df[\"stemmed_statement\"].values:\n",
    "    for word in phrase.split():\n",
    "        fre_count[word] += 1\n",
    "        \n",
    "fre_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_words = set([word for (word, count) in fre_count.most_common(10)])\n",
    "df[\"non_freq_statement\"] = df[\"stemmed_statement\"].apply(lambda x: remove_freqwords(x, fre_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "df[\"lemmatized_statesment\"] = df[\"non_freq_statement\"].apply(lambda x: lemmatize_words(x, WordNetLemmatizer(), wordnet_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>statement</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>non_stop_statement</th>\n",
       "      <th>stemmed_statement</th>\n",
       "      <th>non_freq_statement</th>\n",
       "      <th>lemmatized_statesment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran  the company has no plans to...</td>\n",
       "      <td>1</td>\n",
       "      <td>According to Gran the company has no plans to ...</td>\n",
       "      <td>accord to gran the compani ha no plan to move ...</td>\n",
       "      <td>accord gran ha no plan move all product russia...</td>\n",
       "      <td>accord gran ha no plan move all product russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>technopoli plan to develop in stage an area of...</td>\n",
       "      <td>technopoli plan develop stage an area no less ...</td>\n",
       "      <td>technopoli plan develop stage an area no less ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>the intern electron industri compani elcoteq h...</td>\n",
       "      <td>intern electron industri elcoteq ha laid off t...</td>\n",
       "      <td>intern electron industri elcoteq ha lay off te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>with the new product plant the compani would i...</td>\n",
       "      <td>with new product plant would increas capac mee...</td>\n",
       "      <td>with new product plant would increas capac mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company s updated strategy fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>According to the company updated strategy for ...</td>\n",
       "      <td>accord to the compani updat strategi for the y...</td>\n",
       "      <td>accord updat strategi year baswar target longt...</td>\n",
       "      <td>accord updat strategi year baswar target longt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                          statement  \\\n",
       "0   neutral  According to Gran  the company has no plans to...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company s updated strategy fo...   \n",
       "\n",
       "   sentiment_encoded                                 non_stop_statement  \\\n",
       "0                  1  According to Gran the company has no plans to ...   \n",
       "1                  1  Technopolis plans to develop in stages an area...   \n",
       "2                  0  The international electronic industry company ...   \n",
       "3                  2  With the new production plant the company woul...   \n",
       "4                  2  According to the company updated strategy for ...   \n",
       "\n",
       "                                   stemmed_statement  \\\n",
       "0  accord to gran the compani ha no plan to move ...   \n",
       "1  technopoli plan to develop in stage an area of...   \n",
       "2  the intern electron industri compani elcoteq h...   \n",
       "3  with the new product plant the compani would i...   \n",
       "4  accord to the compani updat strategi for the y...   \n",
       "\n",
       "                                  non_freq_statement  \\\n",
       "0  accord gran ha no plan move all product russia...   \n",
       "1  technopoli plan develop stage an area no less ...   \n",
       "2  intern electron industri elcoteq ha laid off t...   \n",
       "3  with new product plant would increas capac mee...   \n",
       "4  accord updat strategi year baswar target longt...   \n",
       "\n",
       "                               lemmatized_statesment  \n",
       "0  accord gran ha no plan move all product russia...  \n",
       "1  technopoli plan develop stage an area no less ...  \n",
       "2  intern electron industri elcoteq ha lay off te...  \n",
       "3  with new product plant would increas capac mee...  \n",
       "4  accord updat strategi year baswar target longt...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>lemmatized_statesment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>accord gran ha no plan move all product russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>technopoli plan develop stage an area no less ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>intern electron industri elcoteq ha lay off te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>with new product plant would increas capac mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>accord updat strategi year baswar target longt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment_encoded                              lemmatized_statesment\n",
       "0                  1  accord gran ha no plan move all product russia...\n",
       "1                  1  technopoli plan develop stage an area no less ...\n",
       "2                  0  intern electron industri elcoteq ha lay off te...\n",
       "3                  2  with new product plant would increas capac mee...\n",
       "4                  2  accord updat strategi year baswar target longt..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['sentiment','statement','non_stop_statement','stemmed_statement','non_freq_statement'],axis =1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3870,), (968,), (3870,), (968,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.lemmatized_statesment,df.sentiment_encoded,test_size = 0.2 , random_state = 42)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MODEL - LOGISTIC REGRESSION\n",
      "accuracy: 76.45%\n",
      "[[ 60  42  18]\n",
      " [  8 523  44]\n",
      " [  3 113 157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.50      0.63       120\n",
      "           1       0.77      0.91      0.83       575\n",
      "           2       0.72      0.58      0.64       273\n",
      "\n",
      "    accuracy                           0.76       968\n",
      "   macro avg       0.78      0.66      0.70       968\n",
      "weighted avg       0.77      0.76      0.75       968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"Baseline MODEL - LOGISTIC REGRESSION\")\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTINOMIAL NAIVE BAYES\n",
      "accuracy: 70.97%\n",
      "[[ 19  71  30]\n",
      " [  1 562  12]\n",
      " [  0 167 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.16      0.27       120\n",
      "           1       0.70      0.98      0.82       575\n",
      "           2       0.72      0.39      0.50       273\n",
      "\n",
      "    accuracy                           0.71       968\n",
      "   macro avg       0.79      0.51      0.53       968\n",
      "weighted avg       0.74      0.71      0.66       968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"MULTINOMIAL NAIVE BAYES\")\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOST\n",
      "accuracy: 78.2%\n",
      "[[ 71  37  12]\n",
      " [  9 516  50]\n",
      " [  3 100 170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.59      0.70       120\n",
      "           1       0.79      0.90      0.84       575\n",
      "           2       0.73      0.62      0.67       273\n",
      "\n",
      "    accuracy                           0.78       968\n",
      "   macro avg       0.79      0.70      0.74       968\n",
      "weighted avg       0.78      0.78      0.78       968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', GradientBoostingClassifier(loss = 'deviance',\n",
    "                                                   learning_rate = 0.075,\n",
    "                                                   n_estimators = 100,\n",
    "                                                   max_depth = 8,\n",
    "                                                   random_state=42))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"GRADIENT BOOST\")\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
