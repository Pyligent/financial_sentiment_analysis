{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a422be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./env/lib/python3.8/site-packages (4.23.1)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./env/lib/python3.8/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./env/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.8/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.8/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./env/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./env/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512e88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9750d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample ='I will go training tonight'\n",
    "bert_input  = tokenizer(sample,\n",
    "                       padding = 'max_length',\n",
    "                       truncation = True,\n",
    "                       max_length = 10,\n",
    "                       return_tensors ='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052ddeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  146, 1209, 1301, 2013, 3568,  102,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(bert_input.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbd2735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(bert_input.token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b19f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(bert_input.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c2d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decode = tokenizer.decode(bert_input.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f959396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] I will go training tonight [SEP] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(sample_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68bb3bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(bert_input.attention_mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494c5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(bert_input.token_type_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0025eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Class\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22c6445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0376f882d69043fcba186b2b6f12a3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dbe9e6638c49e6a3ba2fcf0dfe9941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01913fad770646ed835f0ea35c914ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "labels = {'background':0,\n",
    "          'objective': 1,\n",
    "          'method':2,\n",
    "          'experiemnt':3,\n",
    "          'conclusion':4\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41c91c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.labels = [labels[label] for label in df['categrory']]\n",
    "        self.texts = [tokenizter(text,\n",
    "                                padding = 'max_length',\n",
    "                                max_lenth = 512,\n",
    "                                trucation =True,\n",
    "                                return_sensor = 'pt')  for text in df['text']]\n",
    "        \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        \n",
    "        return np.array(self.labels[idx])\n",
    "    \n",
    "    def get_batch_texts(self,idx):\n",
    "        \n",
    "        return self.text[idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        batch_text = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        \n",
    "        \n",
    "        return batch_text,batch_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc199f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preparation, split test val\n",
    "\n",
    "np.random.seed(42)\n",
    "df.train, df.val,df.test = np.split(df.sample(frac =1, random_state = 122),\n",
    "                                   [int(.8*len(df), int(.9*len(df))])   #[0-0.8, 0.8-0.9, 0.9-1]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text_orig'],\n",
    "            df['sentiment'],\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320c574",
   "metadata": {},
   "source": [
    "np.split \n",
    "\n",
    "If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split. For example, [2, 3] would, for axis=0, result in\n",
    "ary[:2]\n",
    "ary[2:3]\n",
    "ary[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0962f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building \n",
    "\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856ee29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class BertClassifer(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout=0.5):\n",
    "        \n",
    "        super(BertClassifier,self).__init__()\n",
    "        \n",
    "        \n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768,5)\n",
    "        self.Relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,input_id,mask):\n",
    "        \n",
    "        _,pooled_output = self.bert(input_ids = input_id,\n",
    "                                    attention_mask = mask,\n",
    "                                    return_dict =False)\n",
    "        \n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        \n",
    "        linear_output = self.linear(dropout_output)\n",
    "        \n",
    "        final_layer = self.ReLU(linear_output) # nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        return final_layer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    \n",
    "    # data loader\n",
    "    train, val =Dataset(train_data), Dataset(val_data)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size = 2, shuffle =True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size = 2)\n",
    "    \n",
    "    \n",
    "    # device\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # loss function and optimizer\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizaer = Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    #device\n",
    "    if use_cuda:\n",
    "        \n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "        \n",
    "    # trining loop\n",
    "        \n",
    "    for epoch_num in range(epochs):\n",
    "        \n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            \n",
    "            #model parameters: input_id, mask\n",
    "            \n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeez(1).to(device)\n",
    "            \n",
    "            output = model(input_id,mask)\n",
    "            \n",
    "            # loss\n",
    "            \n",
    "            batch_loss = criterion(output,train_label.long())\n",
    "            total_loss_train +=batch_loss.item()\n",
    "            \n",
    "            \n",
    "            # acc\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "            \n",
    "            \n",
    "            # Gradient compute\n",
    "            model.zero_grad() # init. weights\n",
    "            \n",
    "            batch_loss.backward() # backward pass\n",
    "            optimizaer.step() #gradient descent\n",
    "            \n",
    "            \n",
    "            # val loop\n",
    "            total_loss_val, total_acc_val =0,0\n",
    "            \n",
    "            with torch.no_grad() # perform validation\n",
    "                for val_input, val_label in val_dataloader:\n",
    "                    \n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeez(1).to(device)\n",
    "                    \n",
    "                    output = model(input_id,mask)\n",
    "                    \n",
    "                    \n",
    "                    batch_loss = criterion(output,val_label.long())\n",
    "                    total_loss_val +=batch_loss.item()\n",
    "            \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "                    \n",
    "            \n",
    "            print( f'Epochs: {epoch_num +1} |Train_loss: {total_loss_train/len(train_data):.3f} \\\n",
    "                    | Train Acc: {total_acc_trainlen(train_data):.3f} \\\n",
    "                    | Val_Loss : {total_loss_val/len(val_data):.3f} \\\n",
    "                    | Val Acc: {total_acc_val/len(val_data):.3f} \n",
    "            \n",
    "           \n",
    "            )\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            EPOCHS = 10\n",
    "            model = BertClassfier()\n",
    "            LR =1e-6\n",
    "            \n",
    "            train(model,df_train,df_val, LR,EPOCHS)\n",
    "                    \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d05efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def evaluate(model,test_data):\n",
    "    \n",
    "    \n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size = 2)\n",
    "    \n",
    "     #device\n",
    "        \n",
    "         \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    \n",
    "    if use_cuda:\n",
    "        \n",
    "        model = model.cuda()\n",
    "        \n",
    "    total_test_acc = 0\n",
    "    \n",
    "    with torch.no_grad() # perform validation\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            \n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeez(1).to(device)\n",
    "            \n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            \n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_test_acc +=acc\n",
    "            \n",
    "            \n",
    "        print(f'test acc: {total_test_acc/len(test_data):.3f}')\n",
    "        \n",
    "        \n",
    "evaluate(model, df_test)\n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
